[
  {
    "requirement": "General description of the AI system",
    "requirement_id": "req1",
    "coverage_score": 0.9,
    "matched_terms": [
      "AI System",
      "AI Deployer",
      "AI Provider",
      "intended purpose"
    ],
    "reasoning": "The ontology directly represents an AI System and explicitly defines both AI Deployer and AI Provider, aligning with the requirement to identify the responsible parties. Importantly, the 'intended purpose' property is present, capturing the purpose of the AI system. The combination of these terms adequately covers the requirement, but a more direct linkage between the AI System and its responsible parties (Deployer/Provider) to describe *who* is responsible for the development would be ideal.",
    "missing": [
      "Developer Responsibility",
      "AI System Development Team",
      "Lead Developer"
    ]
  },
  {
    "requirement": "Interaction with hardware/software",
    "requirement_id": "req2",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "Software Component",
      "Hardware Component",
      "Interface",
      "AI Deployer",
      "AI Provider",
      "Software Dependency",
      "Build and Integration Testing",
      "Data Pipeline",
      "Computational Resource",
      "Software Implementation",
      "Model Engineering",
      "Model Packaging",
      "Deployment"
    ],
    "reasoning": "The ontology strongly covers the interaction of the AI system with hardware and software through explicit terms like 'Hardware Component', 'Software Component', 'Software Dependency', and 'Computational Resource'. Further, the lifecycle activities like 'Build and Integration Testing', 'Model Engineering', 'Model Packaging', and 'Deployment' model how these interactions are realized. It also captures the actors involved ('AI Deployer', 'AI Provider') and the overall 'AI System' as the central entity. The inclusion of 'Interface' & 'Data Pipeline' strengthens the modelling of the interaction.",
    "missing": [
      "System Interaction Protocol",
      "Communication Channel",
      "Inter-AI System Communication",
      "API Specification",
      "Runtime Environment",
      "Resource Allocation",
      "System Configuration",
      "Interoperability Standards"
    ]
  },
  {
    "requirement": "Software/firmware versioning",
    "requirement_id": "req3",
    "coverage_score": 0.85,
    "matched_terms": [
      "Software Component",
      "Software Implementation",
      "Model Versioning",
      "AI System",
      "Deployment",
      "Change Log"
    ],
    "reasoning": "The ontology provides several terms that, when combined, address the AI Act requirement.  'Software Component' and 'Software Implementation' obviously cover the software aspect. 'Model Versioning' is crucial for tracking updates. 'Deployment' captures the point when software is integrated. 'Change Log' enables tracking of updates, and 'AI System' provides the overall context. The combination captures the essence of the requirement, though it lacks a direct, unified concept.",
    "missing": [
      "Software Update Mechanism",
      "Firmware Version",
      "Software Dependency Version",
      "Software Release Notes",
      "Configuration Management Record"
    ]
  },
  {
    "requirement": "Deployment forms",
    "requirement_id": "req4",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "Deployment",
      "Interface",
      "AI Deployer",
      "AI Provider",
      "Visual Documentation",
      "intended purpose",
      "has interface",
      "is deployed by",
      "is provided by",
      "has visual documentation"
    ],
    "reasoning": "The ontology covers the requirement well by focusing on the AI System itself, explicitly tracking deployment, and identifying both the deployer and provider involved.  The inclusion of 'Modality' captures *how* the system is provided, and linking to 'Interface' and 'Visual Documentation' addresses different forms of delivery. The linkage to the deploying and providing agent is also excellent, though more granular form factors could be refined.",
    "missing": [
      "Form Factor",
      "Distribution Channel",
      "Service Type (API, Software, Hardware)",
      "Access Method (Cloud, On-Premise)",
      "Packaging (container, executable, library)"
    ]
  },
  {
    "requirement": "Hardware required",
    "requirement_id": "req5",
    "coverage_score": 0.95,
    "matched_terms": [
      "Hardware Component",
      "Computational Resource",
      "resource type",
      "resource vendor",
      "resource configuration",
      "AI System",
      "AI Deployer",
      "AI Provider"
    ],
    "reasoning": "The ontology provides a dedicated `Hardware Component` class, along with detailed properties for describing `Computational Resource` aspects like type, vendor, and configuration.  Linking the `AI System` to the necessary hardware via `requires hardware` satisfies the requirement. Including `AI Deployer` and `AI Provider` acknowledges who is responsible for ensuring the hardware is appropriate and meets requirements.",
    "missing": [
      "Hardware Specification",
      "Minimum Hardware Requirements",
      "Operating Environment"
    ]
  },
  {
    "requirement": "Illustrations and markings",
    "requirement_id": "req6",
    "coverage_score": 0.95,
    "matched_terms": [
      "AI System",
      "Visual Documentation",
      "intended purpose",
      "has visual documentation",
      "depicts"
    ],
    "reasoning": "The ontology explicitly includes 'Visual Documentation' and a property 'has visual documentation' to link AI systems to such documentation. ‘AI System’ directly represents the item being documented, and the ‘depicts’ property allows for specifying *what* the documentation shows (external features, internal layout, markings). The ‘intended purpose’ can provide context for the documentation being required, and therefore related to the feature of the product itself. This closely aligns with the AI Act requirement.",
    "missing": [
      "Product Feature Documentation",
      "Hardware/Software Configuration Documentation"
    ]
  },
  {
    "requirement": "User interface for deployer",
    "requirement_id": "req7",
    "coverage_score": 0.85,
    "matched_terms": [
      "Interface",
      "AI System",
      "Visual Documentation",
      "Deployment",
      "intended purpose",
      "modality"
    ],
    "reasoning": "The requirement focuses on the *user interface* provided to the deployer. 'Interface' directly represents the UI. 'AI System' is the entity to which the interface belongs. 'Visual Documentation' and 'Deployment' are closely related as the interface is part of the deployed system’s documentation and access method. The terms 'intended purpose' and 'modality' help define the context of the UI, detailing what the AI is meant to do and how it presents itself. The combination strongly captures the essence of the requirement.",
    "missing": [
      "User Experience (UX) Specifications",
      "Accessibility Features",
      "Interaction Patterns"
    ]
  },
  {
    "requirement": "Elements of system and development process",
    "requirement_id": "req8",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "AI Activity",
      "AI Artifact",
      "Software Component",
      "Hardware Component",
      "AI Model",
      "AI Method",
      "Data Pipeline",
      "Software Code Pipeline",
      "Machine Learning Pipeline",
      "Dataset",
      "Data Training",
      "Data Validation",
      "Data Testing",
      "Model Engineering",
      "Model Packaging",
      "Build and Integration Testing",
      "Change Log",
      "Data Wrangling/Cleaning",
      "Software Implementation",
      "Training Data Sheet",
      "intended purpose",
      "has component",
      "has software component",
      "depends on"
    ],
    "reasoning": "The ontology provides a strong base for representing the elements and processes of an AI system's development. It covers the system’s architecture, software and hardware components, data processing stages, model training/validation/testing, and change management. However, it doesn't explicitly link the *development process* as a cohesive activity beyond individual activities, making detailed process documentation a bit fragmented. The properties *has component* and *depends on* help connect things, but dedicated process modelling is missing.",
    "missing": [
      "AI System Development Lifecycle",
      "Development Process Documentation",
      "System Architecture Description",
      "Development Environment Configuration",
      "Release Management Procedures",
      "Version Control System Details"
    ]
  },
  {
    "requirement": "System architecture and algorithms",
    "requirement_id": "req9",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "Software Component",
      "AI Method",
      "Software Implementation",
      "Model Engineering",
      "AI Artifact",
      "version",
      "has software component",
      "uses AI method",
      "intended purpose",
      "modality"
    ],
    "reasoning": "The ontology comprehensively covers the structural aspects of the AI system ('AI System', 'Software Component', 'has software component') and the implementation details ('Software Implementation', 'AI Method', 'uses AI method'). The inclusion of 'Model Engineering' acknowledges the design phase, and 'Architecture' explicitly addresses system architecture. The inclusion of 'version', 'intended purpose', and 'modality' touch upon other important aspects of system description, however, the detail of the algorithms isn't explicitly captured as a separate, readily linkable concept beyond their association with methods.",
    "missing": [
      "Algorithm Detail",
      "Algorithm Input/Output Specification",
      "Algorithm Complexity",
      "Algorithm Training Parameters",
      "Algorithm Decision Logic"
    ]
  },
  {
    "requirement": "Data requirements",
    "requirement_id": "req10",
    "coverage_score": 0.95,
    "matched_terms": [
      "Dataset",
      "Data Training",
      "Data Validation",
      "Data Testing",
      "Data Pipeline",
      "Data Wrangling/Cleaning",
      "Data Acquisition Activity",
      "Data Sheet",
      "Training Data Sheet",
      "Labeling Procedure",
      "Data Cleaning Procedure"
    ],
    "reasoning": "The ontology provides detailed coverage of data requirements, including dataset representations, data lifecycle activities (acquisition, training, validation, testing, wrangling), and crucial metadata described within data sheets. The inclusion of specific properties detailing data scope, characteristics, and collection methods, and procedures for data cleaning and labeling further strengthens the coverage. It excels in representing the \"what, how, and where\" of AI data.",
    "missing": [
      "Data Format",
      "Data Provenance",
      "Data Source Details (beyond collection method)"
    ]
  },
  {
    "requirement": "Training, validation, testing data",
    "requirement_id": "req11",
    "coverage_score": 0.85,
    "matched_terms": [
      "Dataset",
      "Data Training",
      "Data Validation",
      "Data Testing",
      "Data Acquisition Activity",
      "Data Pipeline",
      "Training Data Sheet",
      "Labeling Procedure",
      "Data Cleaning Procedure"
    ],
    "reasoning": "The ontology comprehensively covers the data aspects of the AI Act requirement. It establishes connections between datasets and the training, validation, and testing activities. The addition of terms relating to data sheets and cleaning procedures strengthens coverage of provenance and documentation. The only slight gap is explicit linking of the 'provenance' aspect to a broader understanding of data lifecycle tracking.",
    "missing": [
      "Data Provenance",
      "Data Documentation Standard",
      "Data Access Control",
      "Data Retention Policy"
    ]
  },
  {
    "requirement": "Measures for data quality",
    "requirement_id": "req12",
    "coverage_score": 0.85,
    "matched_terms": [
      "Data Wrangling/Cleaning",
      "Data Pipeline",
      "Data Training",
      "Data Validation",
      "Data Testing",
      "Data Cleaning Procedure",
      "Labeling Procedure",
      "Training Data Sheet",
      "Data Wrangling/Cleaning",
      "Data Pipeline",
      "Data Sheet"
    ],
    "reasoning": "The ontology provides a strong representation of data quality assurance activities, particularly through the specific 'Data Cleaning Procedure' and 'Labeling Procedure' terms, alongside the broader 'Data Pipeline' and general data activity terms. The inclusion of 'Training Data Sheet', 'Outlier Handling Method', and data metrics capture important components of ensuring data quality. While the ontology captures the *activities*, it is less explicit about the documentation and records for processes, requiring inference of how these are captured.",
    "missing": [
      "Data Quality Report",
      "Data Provenance Record",
      "Data Audit Trail",
      "Data Quality Assurance Plan"
    ]
  },
  {
    "requirement": "Training methodologies",
    "requirement_id": "req13",
    "coverage_score": 0.9,
    "matched_terms": [
      "Data Training",
      "Data Validation",
      "Data Testing",
      "Data Wrangling/Cleaning",
      "Dataset",
      "Training Data Sheet",
      "Computational Resource",
      "Machine Learning Pipeline",
      "Model Engineering",
      "Software Implementation",
      "Software Component",
      "Data Pipeline",
      "Data Acquisition Activity",
      "Log",
      "Data Monitoring and Logging"
    ],
    "reasoning": "The ontology provides strong coverage of the AI Act requirement by explicitly modelling data usage (datasets, training/validation/testing), training activities (Data Training, Model Engineering), and computational resources.  It also covers the pipeline aspects and logging which is implicit in a detailed methodology description. The granularity of specific configurations is present through 'Computational Resource' and related attributes. While configuration details *can* be represented, they are not first-class citizens of the ontology.",
    "missing": [
      "Hyperparameter Configuration",
      "Training Procedure Details",
      "Configuration Script",
      "Data Versioning",
      "Experiment Tracking",
      "Model Architecture"
    ]
  },
  {
    "requirement": "Testing and validation procedures",
    "requirement_id": "req14",
    "coverage_score": 0.9,
    "matched_terms": [
      "AI System",
      "AI Activity",
      "Data Training",
      "Data Validation",
      "Data Testing",
      "Model Engineering",
      "Model Evaluation",
      "Computational Resource",
      "Hardware Component",
      "Software Component",
      "AI Deployer",
      "AI Provider",
      "Machine Learning Pipeline",
      "Software Implementation"
    ],
    "reasoning": "The ontology adequately represents the requirement for describing testing and validation procedures, including computational resources. Terms like 'AI System,' 'AI Activity', and specific data/model activities (training, validation, testing) cover the *what* is being tested/validated.  'Computational Resource' and 'Hardware Component' directly address the resources used, and terms like ‘AI Deployer’ and ‘AI Provider’ identify responsible parties. The coverage is high but not perfect, as fine-grained details about *how* the testing/validation is performed isn't directly captured.",
    "missing": [
      "Test Plan",
      "Validation Protocol",
      "Test Environment Configuration",
      "Performance Benchmark",
      "Test Data Set Characteristics"
    ]
  },
  {
    "requirement": "Risk management system",
    "requirement_id": "req15",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "AI Deployer",
      "AI Provider",
      "AI Activity",
      "AI Agent",
      "Data Acquisition Activity",
      "Data Pipeline",
      "Model Engineering",
      "Model Evaluation",
      "Deployment",
      "Post-market Monitoring Activity",
      "Post-market Performance Evaluation Activity",
      "Human Oversight Mechanism",
      "Data Validation",
      "Data Testing",
      "Data Wrangling/Cleaning",
      "Change Log",
      "Data Sheet",
      "Training Data Sheet",
      "Labeling Procedure",
      "Data Cleaning Procedure",
      "intended purpose",
      "version",
      "frequency",
      "has lifecycle stage",
      "is deployed by",
      "is provided by",
      "has risk"
    ],
    "reasoning": "The ontology strongly covers the requirement by representing all key agents (deployer, provider) and activities (data processing, model building, deployment, monitoring) necessary for a risk management system. The inclusion of 'Risk,' along with lifecycle stages, monitoring activities, and documentation terms (Data Sheet, Change Log), demonstrates the ontology’s capacity to model the system. The focus on data quality procedures also directly supports risk management. The relatively high score reflects the detailed level of granularity related to AI lifecycle aspects.",
    "missing": [
      "Risk Assessment Procedure",
      "Risk Mitigation Plan",
      "Risk Tolerance Level",
      "Incident Reporting Procedure",
      "Compliance Monitoring Procedure",
      "Audit Trail",
      "Corrective Action Plan",
      "Risk Register",
      "Risk Owner"
    ]
  },
  {
    "requirement": "Post-market monitoring",
    "requirement_id": "req16",
    "coverage_score": 0.85,
    "matched_terms": [
      "Post-market Monitoring Activity",
      "Post-market Performance Evaluation Activity",
      "Data Monitoring and Logging",
      "Log",
      "AI System",
      "AI Deployer",
      "is deployed by",
      "has lifecycle stage",
      "Data Cleaning Procedure",
      "has risk"
    ],
    "reasoning": "The ontology provides strong coverage of the post-market monitoring requirement with dedicated terms for the activities and logging involved. It also links related concepts such as the AI system, deployer, and lifecycle stage. The inclusion of data cleaning procedures and risk assessment further strengthens coverage, because post-market monitoring inherently involves identifying failures or unexpected behavior, which ties into risk. The terms provide a solid foundation for representing the required system.",
    "missing": [
      "Incident Reporting",
      "Corrective Actions",
      "Key Performance Indicators (KPIs) for Post-Market Performance",
      "Adverse Event Detection",
      "Feedback Mechanism (from users/operators)",
      "Root Cause Analysis",
      "Alerting System"
    ]
  },
  {
    "requirement": "Cybersecurity measures",
    "requirement_id": "req17",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "Software Component",
      "Software Implementation",
      "Software Dependency",
      "Data Pipeline",
      "Data Wrangling/Cleaning",
      "Data Monitoring and Logging",
      "Data Validation",
      "Data Testing",
      "Log",
      "Computational Resource",
      "Hardware Component",
      "AI Deployer",
      "AI Provider",
      "Change Log",
      "Interface"
    ],
    "reasoning": "The ontology provides strong coverage for the cybersecurity aspects by focusing on the system's components (software, hardware, data pipeline), monitoring & logging, data quality control (validation, testing, cleaning), and dependency management – all crucial for security. It also captures the actors involved (deployer, provider) and tracking changes (changelog). The inclusion of computational resource and interface details enhances the coverage of potential attack surfaces. Though not explicitly labeled as cybersecurity, these areas collectively contribute to building a secure AI system.",
    "missing": [
      "Vulnerability Assessment",
      "Incident Response Plan",
      "Security Audit",
      "Encryption Method",
      "Access Control Mechanism",
      "Network Security Configuration",
      "Data Security Procedure",
      "Threat Modeling",
      "Security Patch Management"
    ]
  },
  {
    "requirement": "Accuracy, robustness, resilience",
    "requirement_id": "req18",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "Model Evaluation",
      "Data Validation",
      "Data Testing",
      "Data Training",
      "Software Implementation",
      "Software Component",
      "Data Wrangling/Cleaning",
      "Hardware Component",
      "Data Pipeline",
      "Machine Learning Pipeline",
      "Change Log",
      "Data Monitoring and Logging",
      "Post-market Monitoring Activity",
      "Post-market Performance Evaluation Activity",
      "intended purpose",
      "version",
      "Software Dependency"
    ],
    "reasoning": "The ontology provides strong coverage for accuracy (via data validation & testing, model evaluation), robustness (through monitoring, change logs, and performance evaluation), and cybersecurity (implied through software implementation, dependencies, and risk assessment).  It comprehensively covers the AI lifecycle stages needed to address these aspects, tracking data lineage and system components. However, specific cybersecurity *measures* are not explicitly modelled, and the linkage between system components and specific security configurations is weak.",
    "missing": [
      "Security Configuration",
      "Vulnerability Assessment",
      "Threat Modeling",
      "Security Audit Log",
      "Incident Response Plan",
      "Data Encryption",
      "Access Control Mechanism",
      "Penetration Testing",
      "Secure Coding Practice",
      "Fuzz Testing"
    ]
  },
  {
    "requirement": "Human oversight mechanisms",
    "requirement_id": "req19",
    "coverage_score": 0.85,
    "matched_terms": [
      "Human Oversight Mechanism",
      "AI System",
      "AI Deployer",
      "AI Activity",
      "has human oversight",
      "is deployed by",
      "intended purpose",
      "Data Monitoring and Logging",
      "Post-market Monitoring Activity",
      "Post-market Performance Evaluation Activity",
      "Change Log"
    ],
    "reasoning": "The ontology directly represents 'Human Oversight Mechanism' and links it to AI systems.  It also covers the deployer and the activities linked to monitoring, logging, and change management, all crucial aspects of human oversight. The inclusion of 'intended purpose' is relevant, as oversight needs to consider how the system *should* be used. However, it lacks granular details regarding the *types* of human oversight mechanisms, or the specific processes for escalating issues.",
    "missing": [
      "Oversight Procedure",
      "Escalation Protocol",
      "Human-in-the-Loop Process",
      "Fallback Mechanism",
      "Oversight Responsibility",
      "Intervention Trigger",
      "Oversight Documentation",
      "Human Oversight Report"
    ]
  },
  {
    "requirement": "Transparency for users",
    "requirement_id": "req20",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "Transparency Measure",
      "has transparency measure",
      "Visual Documentation",
      "has visual documentation",
      "Software Component",
      "Software Implementation",
      "Data Sheet",
      "Training Data Sheet",
      "Model Engineering",
      "Change Log",
      "Data Pipeline",
      "Machine Learning Pipeline",
      "Software Code Pipeline"
    ],
    "reasoning": "The ontology provides several terms directly or indirectly related to transparency, particularly around documentation, system components, and data provenance. The 'Transparency Measure' and 'has transparency measure' relationships are central, while terms like 'Visual Documentation', 'Data Sheet', and pipeline descriptions contribute to detailing *how* transparency is achieved. The inclusion of versioning through 'Change Log' and documentation of the building process add to a complete picture. However, detailed specification of *what* technically constitutes transparency is missing.",
    "missing": [
      "Explainability Report",
      "Model Card",
      "Traceability Matrix",
      "Algorithmic Transparency Report",
      "Technical Documentation Standard",
      "Transparency Method",
      "Transparency Audit Report"
    ]
  },
  {
    "requirement": "Logging capabilities",
    "requirement_id": "req21",
    "coverage_score": 0.85,
    "matched_terms": [
      "Data Monitoring and Logging",
      "Log",
      "AI Activity",
      "AI System",
      "Deployment",
      "Post-market Monitoring Activity",
      "Post-market Performance Evaluation Activity",
      "AI Deployer",
      "Data Pipeline",
      "Software Component",
      "has lifecycle stage"
    ],
    "reasoning": "The ontology provides robust terms relating to data logging and monitoring (Data Monitoring and Logging, Log) as well as capturing the broader AI lifecycle activities and actors (AI Activity, AI System, AI Deployer). The inclusion of Deployment and Post-market activities directly addresses the requirements of logging throughout the AI system's lifespan. Additional terms like Data Pipeline and Software Component demonstrate the ability to model the flow and components required for logging data. However, the ontology doesn’t explicitly tie logging requirements directly to legal compliance articles like the AI Act.",
    "missing": [
      "AI Act Compliance Requirement",
      "Compliance Logging Configuration",
      "Audit Trail",
      "Retention Policy",
      "Access Control for Logs",
      "Security Logging",
      "Automated Logging Verification"
    ]
  },
  {
    "requirement": "Lifecycle performance assurance",
    "requirement_id": "req22",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "AI System Capability",
      "AI Activity",
      "Data Monitoring and Logging",
      "Post-market Monitoring Activity",
      "Change Log",
      "Software Component",
      "Hardware Component",
      "Performance Metric",
      "Deployment",
      "Model Versioning",
      "Human Oversight Mechanism"
    ],
    "reasoning": "The ontology robustly covers the need to demonstrate consistent performance over the AI system's lifecycle. Terms like 'AI System', 'AI Activity' (particularly 'Deployment', 'Post-market Monitoring Activity'), 'Change Log', and 'Version' indicate a focus on tracking the system's evolution and behavior over time. Metrics and components contribute to demonstrating and monitoring consistency. However, the ontology lacks direct representations of *predictability* or *stability* which are core to consistent performance.",
    "missing": [
      "System Stability",
      "Performance Degradation Rate",
      "Predictability metric",
      "Drift Detection Mechanism",
      "Failure Mode Analysis",
      "Performance Baseline"
    ]
  },
  {
    "requirement": "Appropriateness of performance metrics",
    "requirement_id": "req23",
    "coverage_score": 0.85,
    "matched_terms": [
      "Performance Metric",
      "Model Evaluation",
      "Data Validation",
      "Data Testing",
      "AI System",
      "AI Task",
      "intended purpose",
      "AI System Capability"
    ],
    "reasoning": "The ontology directly covers performance metrics and evaluation activities. Importantly, ‘intended purpose’ is crucial since appropriateness is inherently tied to whether a metric *effectively* measures performance *for the AI System's function.* The 'AI System Capability' links the system's performance to its intended function. Linking these terms sufficiently addresses the AI Act's requirement, however, finer granularity in the *criteria* for appropriateness is missing.",
    "missing": [
      "Performance Metric Appropriateness Criteria",
      "Performance metric relevance",
      "Performance metric bias assessment"
    ]
  },
  {
    "requirement": "Risk management (detailed)",
    "requirement_id": "req24",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "AI Deployer",
      "AI Provider",
      "AI Activity",
      "Data Acquisition Activity",
      "Data Wrangling/Cleaning",
      "Data Training",
      "Data Validation",
      "Data Testing",
      "Model Engineering",
      "Model Evaluation",
      "Deployment",
      "Post-market Monitoring Activity",
      "Post-market Performance Evaluation Activity",
      "Change Log",
      "Human Oversight Mechanism",
      "Data Sheet",
      "Training Data Sheet",
      "Labeling Procedure",
      "Data Cleaning Procedure",
      "Software Component",
      "Software Implementation",
      "intended purpose",
      "version",
      "frequency"
    ],
    "reasoning": "The ontology provides strong coverage of the risk management system requirement by identifying key actors (Deployer, Provider) and activities throughout the AI lifecycle (data acquisition, training, deployment, post-market monitoring). The inclusion of 'Risk', 'Change Log', and data-related procedures further supports risk identification and mitigation. However, detailed aspects of risk assessment, mitigation strategies, and specific documentation requirements are not fully captured.",
    "missing": [
      "Risk Assessment Procedure",
      "Risk Mitigation Strategy",
      "Risk Register",
      "Incident Reporting Procedure",
      "Corrective Action Plan",
      "Risk Monitoring Plan",
      "Compliance Audit Log",
      "Security Vulnerability Assessment",
      "Data Governance Policy",
      "Bias Detection Method",
      "Adverse Event Management",
      "Risk Acceptance Criteria"
    ]
  },
  {
    "requirement": "Changes to the system lifecycle",
    "requirement_id": "req25",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "AI Activity",
      "Change Log",
      "AI System Capability",
      "AI Model",
      "Software Implementation",
      "Software Component",
      "Build and Integration Testing",
      "Machine Learning Pipeline",
      "Data Pipeline",
      "Software Code Pipeline",
      "Model Engineering",
      "Model Packaging",
      "Model Versioning",
      "Deployment",
      "Post-market Monitoring Activity",
      "Post-market Performance Evaluation Activity"
    ],
    "reasoning": "The ontology comprehensively covers the lifecycle of an AI system, including build, testing, deployment, and post-market activities. Terms related to versioning, component changes, and the overall AI system lifecycle directly address the requirement to track changes. Linking these to specific AI Activity stages (e.g., build, deployment, monitoring) allows for detailed change tracking, achieving high coverage. However, more granular tracking of *what specifically* changed about each component (e.g., code commits, data schema changes) is not explicitly modeled.",
    "missing": [
      "Software Change Request",
      "Patch",
      "Rollback Procedure",
      "Configuration Change",
      "System Log",
      "Data Schema Change",
      "Incident Report",
      "Audit Trail"
    ]
  },
  {
    "requirement": "Applied standards",
    "requirement_id": "req26",
    "coverage_score": 0.85,
    "matched_terms": [
      "AI System",
      "Standard",
      "Declaration of Conformity",
      "AI Provider",
      "AI Deployer",
      "Visual Documentation",
      "Change Log",
      "Data Sheet",
      "Training Data Sheet",
      "Software Component",
      "Software Dependency"
    ],
    "reasoning": "The ontology adequately represents the requirement by linking the AI System to applied Standards and a Declaration of Conformity, and identifying the AI Provider and Deployer associated with it. It also includes supporting elements like visual documentation and even change logs, which are important for maintainability and demonstrability of compliance. The inclusion of data sheets and software dependencies round out the coverage. However, a more explicit representation of 'standards applied' as a property on the AI system beyond just 'applies standard', or inclusion of specific standard identifiers or version numbers could improve precision.",
    "missing": [
      "Harmonized Standard Identifier",
      "Compliance Document",
      "Standards Version",
      "Compliance Report/Audit Trail"
    ]
  },
  {
    "requirement": "EU Declaration of Conformity",
    "requirement_id": "req27",
    "coverage_score": 0.95,
    "matched_terms": [
      "Declaration of Conformity",
      "AI System",
      "AI Provider",
      "AI Deployer"
    ],
    "reasoning": "The ontology directly represents a 'Declaration of Conformity' as an artifact. It also clearly defines 'AI System', 'AI Provider', and 'AI Deployer', which are parties intrinsically involved in creating or utilizing a system requiring such a declaration. The link 'has declaration of conformity' directly connects an AI system to its declaration. The coverage is high as the core requirement is modeled; however, the specific *process* of creating or verifying the declaration isn't fully represented.",
    "missing": [
      "Compliance Verification Activity",
      "Conformity Assessment Procedure",
      "Regulatory Requirement"
    ]
  },
  {
    "requirement": "Post-market performance evaluation",
    "requirement_id": "req28",
    "coverage_score": 0.85,
    "matched_terms": [
      "Post-market Monitoring Activity",
      "Post-market Performance Evaluation Activity",
      "Data Monitoring and Logging",
      "AI System",
      "AI Deployer",
      "AI Provider",
      "Performance Metric",
      "Change Log",
      "Log",
      "Data Cleaning Procedure"
    ],
    "reasoning": "The ontology terms provide a strong foundation for representing the post-market evaluation system. Terms like 'Post-market Monitoring Activity' and 'Post-market Performance Evaluation Activity' directly address the requirement. The 'Data Monitoring and Logging', 'AI System', 'AI Deployer', and 'AI Provider' terms establish the actors and the subject matter. 'Performance Metric', 'Change Log', and 'Log' terms represent data capture aspects of the evaluation. The addition of data quality procedures captures a layer of checking and quality assurance.",
    "missing": [
      "Incident Reporting Procedure",
      "Feedback Mechanism",
      "Root Cause Analysis",
      "Remediation Plan",
      "System Performance Thresholds",
      "Escalation Procedures"
    ]
  }
]